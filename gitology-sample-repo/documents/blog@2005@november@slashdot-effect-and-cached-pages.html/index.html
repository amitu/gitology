<p><div style="clear:both;"></div>Came across this on <a href="http://slashdot.org/faq/suggestions.shtml#su900">/. FAQ</a>:<br /><blockquote><h3>Slashdot should cache pages to prevent the Slashdot Effect!</h3> <p>Sure, it's a great idea, but it has a lot of implications. For example, commercial sites rely on their banner ads to generate revenue. If I cache one of their pages, <span style="font-style: italic;">this will mess with their statistics, and mess with their banner ads. In other words, this will piss them off.</span></p> <p>Of course, most of the time, the commercial sites that actually have income from banner ads easily withstand the Slashdot Effect. So perhaps we could draw the line at sites that don't have ads. They are, after all, much more likely to buckle under the pressure of all those unexpected hits. But what happens if I cache the site, and they update themselves? Once again, I'm transmitting data that I shouldn't be, only this time my cache is out of date!</p> <p>I could try asking permission, but do you want to wait 6 hours for a cool breaking story while we wait for permission to link someone?</p> <p>So the quick answer is: "Sure, caching would be neat." It would make things a lot easier when servers go down, but it's a complicated issue that would need to be thought through in great detail before being implemented.</p> <p><em><small>                 Answered by: <a href="mailto:malda@slashdot.org">CmdrTaco</a><br />              Last Modified: 6/14/00         </small></em></p> <h3>Is it possible to have META tags that Slashdot looks for in a story link before allowing it to be submitted/posted? Many times a server can't handle the load of a Slashdotting. So can the site have tags to prevent it from being added to a Slashdot story?</h3> <p>Not inconceivable, but I don't really think it's worth the work. Most of the sites that are Slashdotted are prepared for it, and the sites that get smashed usually are caught completely off guard; they wouldn't know of this mysterious opt-out meta tag. (See also <a href="http://slashdot.org/faq/suggestions.shtml#su900">Caching Slashdot Stories</a>).</p> <p><em><small>                 Answered by: <a href="mailto:malda@slashdot.org">CmdrTaco</a><br />              Last Modified: 10/28/00         </small></em></p></blockquote></p><p>To me this is plainly stupid. "Slashdotting" is a very real phenomena, it happen quite frequently too, and its annoying, atleast for slashdot regulars: you read slashdot regularly, keep pressing reload every five min. to see a new story, and when it comes, you cant access the linked site! Some unsuspecting sysadmin suffers too in the process. Caching pages is the solution and if the reason why they don't do it is: "this will mess with their statistics, and mess with their banner ads. In other words, this will piss them off."; then why don't they follow the perfectly standard way of caching site based on <a href="http://en.wikipedia.org/wiki/Robots.txt">robot.txt</a>. If a site does not want its pages to be cached by slashdot for any reason, they can just add a line in their robot.txt. Very lame CmdrTaco!<br /></p><div style="clear:both; padding-bottom: 0.25em;"></div>